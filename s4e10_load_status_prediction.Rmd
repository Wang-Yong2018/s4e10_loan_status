---
title: "s4e10_load_approval_status"
author: "WangYong"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# load data
```{r}
library(tidyverse)
library(tidymodels)
#library( ParBayesOptimization)
library(themis)
competition_name <- 'playground-series-s4e10'
data_path <- '../input/playground-series-s4e10/'
train <- read_csv(file.path(data_path, "train.csv"),show_col_types=F) |> 
  mutate(loan_status=as.factor(loan_status)) 
test <- read_csv(file.path(data_path, "test.csv"),show_col_types=F) 
sample_submission <- read_csv(file.path(data_path, "sample_submission.csv"),show_col_types = FALSE) 
```
# EDA
## quick skim
```{r}
train|> ggplot(aes(x=loan_status))+geom_bar()
skimr::skim(train)
skimr::skim(test)
```

# split the data 
```{r}
set.seed(1353)

split <- initial_split(train, prop = 0.8, strata = loan_status)
train_data <- training(split)
test_data <- testing(split)

cv_folds <- vfold_cv(train_data, v = 10, strata = loan_status)

```

# feature engineering 
## recipes
### baseline
```{r}
rcp_baseline <-
  recipe(loan_status ~ ., data = train_data) |>
  update_role(id, new_role='ID', )|>
  step_mutate(loan_status=as.factor(loan_status),skip=T)|>
  step_log(all_numeric_predictors(),offset = 1, skip = FALSE) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_impute_median(all_numeric_predictors())|> 
  step_nzv(all_predictors())|>
  step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())|> # Scale numeric predictors
  step_upsample(loan_status, over_ratio = 1)|>
  check_missing(all_predictors())

rcp_baseline |>prep()|>juice() |>glimpse()
```

### v1 bad - baseline + age + income + loan_amnt
first plot eda for age, income and loan_amnt
```{r}
train |>
  select(person_age, person_income, loan_amnt) |>
  pivot_longer(everything(), names_to = "variable", values_to = "value") |>
  ggplot(aes(x = value)) +
  geom_density() +
  theme_minimal()+
  facet_wrap(~variable, ncol = 3, scales = "free")
```

```{r}
rcp_bs_v1 <-
  recipe(loan_status ~ ., data = train_data) |>
  update_role(id, new_role='ID', )|>
  step_mutate(loan_status=as.factor(loan_status),skip=T)|>
    # Step 1: Handle Outliers in person_age (Winsorizing)
  step_mutate(person_age = ifelse(person_age > 80, 80,person_age) ) %>% #Winsorizing step
  # Step 2: Log transformation for Income and Loan Amount
  #step_log(person_income, base = 10) %>%  #Use the log transformation
  #step_log(loan_amnt, base = 10) %>% #Use the log transformation
  step_log(all_numeric_predictors(),base=10,offset = 1, skip = FALSE) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_impute_median(all_numeric_predictors())|> 
  step_nzv(all_predictors())|>
  step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())|> # Scale numeric predictors
  step_upsample(loan_status, over_ratio = 1)|>
  check_missing(all_predictors())

rcp_bs_v1 |>prep()|>juice() |>glimpse()
```
### v2 baseline + interative fe
```{r}
rcp_bs_v2 <-
  recipe(loan_status ~ ., data = train_data) |>
  update_role(id, new_role='ID', )|>
  step_mutate(loan_status=as.factor(loan_status),skip=T)|>
  step_mutate(interest_rate = loan_amnt * loan_int_rate,
              #: Total interest paid might be insightful.
              debt_rate = loan_amnt / person_income , 
              #: Debt-to-income ratio (a variation).
              age_emp_rate = person_age * person_emp_length
              #: Experience can be a factor in loan repayment.
  )|>
  step_log(all_numeric_predictors(),offset = 1, skip = FALSE) |>
  step_normalize(all_numeric_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_impute_median(all_numeric_predictors())|>
  step_nzv(all_predictors())|>
  step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())|> # Scale numeric predictors
  step_upsample(loan_status, over_ratio = 1)|>
  check_missing(all_predictors())

rcp_bs_v2 |>prep()|>juice() |>glimpse()
```
### v3 baseline + smote
```{r}
rcp_bs_v3 <-
  recipe(loan_status ~ ., data = train_data) |>
  update_role(id, new_role='ID', )|>
  step_mutate(loan_status=as.factor(loan_status),skip=T)|>
  step_log(all_numeric_predictors(),offset = 1, skip = FALSE) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_impute_median(all_numeric_predictors())|> 
  step_nzv(all_predictors())|>
  step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())|> # Scale numeric predictors
  step_smote(loan_status, over_ratio = 1)|>
  check_missing(all_predictors())

rcp_bs_v3 |>prep()|>juice() |>glimpse()
```


### selected_recipes
```{r}
selected_list <- 
  list(baseline = rcp_baseline,
       #bs_v1 = rcp_bs_v1,
       bs_v2 = rcp_bs_v2,
       bs_v3 = rcp_bs_v3)
```


# modeling 
## model engine setup
```{r}
  
library(bonsai)
library(lightgbm)

glm_model <- 
  logistic_reg() |>
  set_engine("glm", family = "binomial")|>
  set_mode('classification')

lgbm_model <- 
  boost_tree(
   trees = 500,
   tree_depth = 7,
   learn_rate =  0.1,
   min_n = 80,
   loss_reduction = 0.001
  ) %>% 
  set_engine(engine = "lightgbm",
             is_unbalance = TRUE,
             metric='auc',
             num_leaves = 80,
             num_threads = 12,
             verbose=1
       #      boosting = "goss"   # this may slow the system
             ) %>%
  set_mode(mode = "classification") 

roc_metrics <- metric_set(accuracy, precision, recall, f_meas, roc_auc)

ctrl <- control_resamples(save_pred = TRUE,
                          verbose=TRUE,
                          allow_par= TRUE)
```



## fit
### glm
```{r}
glm_fit_list <-
  selected_list |>
  map(\(x) workflow() |>
           add_model(glm_model)|>
           add_recipe(x)|>
           fit_resamples(cv_folds, control = ctrl, metrics = roc_metrics))

fit_result_df <- 
  glm_fit_list |>
  map_dfr(\(x) collect_metrics(x),.id = 'wflow_id')


```
#### validate

```{r}
glm_fit_result <-
  glm_fit_list |>
  map(\(x) predict(x, test_data, type='prob')|>
           bind_cols(test_data|>mutate(loan_status=factor(loan_status, levels = c(0, 1))))
      )

glm_fit_result |> 
  map_dfr(\(x) x|>
           roc_auc(loan_status, .pred_0,event_level = 'first'),
          .id='model_name')

glm_roc_curve <-
  glm_fit_result|> 
  map(\(x) x|>
           roc_curve(loan_status, .pred_0,event_level = 'first')
          )
  
glm_roc_curve |> 
  map(\(x)  autoplot(x))
  

```
### lightgbm
```{r}
lgbm_fit_list <-
  selected_list |>
  map(\(x) workflow() |>
           add_model(lgbm_model)|>
           add_recipe(x)|>
           fit_resamples(cv_folds, control = ctrl, metrics = roc_metrics))

fit_result_df <- 
  lgbm_fit_list |>
  map_dfr(\(x) collect_metrics(x),.id = 'wflow_id')
fit_result_df|>filter(.metric=='roc_auc')
```
#### validate

```{r}
lgbm_fit_result <-
  lgbm_fit_list |>
  map(\(x) predict(x, test_data, type='prob')|>
           bind_cols(test_data|>mutate(loan_status=factor(loan_status, levels = c(0, 1))))
      )

lgbm_fit_result |> 
  map_dfr(\(x) x|>
           roc_auc(loan_status, .pred_0,event_level = 'first'),
          .id='model_name')

lgbm_roc_curve <-
  lgbm_fit_result|> 
  map(\(x) x|>
           roc_curve(loan_status, .pred_0,event_level = 'first')
          )
  
lgbm_roc_curve |> 
  map(\(x)  autoplot(x))
  
```
## workflowsets
```{r}
library(workflowsets)
# all_metrics 定义了要计算的评估指标 (准确率, 精确率, 召回率, F1-score, AUC)


race_results <- 
  workflows <-
  workflow_set(
    preproc = selected_list,
    models = list(glm = glm_model, lgbm = lgbm_model)
  )|>
  workflow_map(
    "fit_resamples", #快速对比模型方案
    resamples = cv_folds,
    metrics = metric_set(accuracy, precision, recall, f_meas, roc_auc), #roc_auc需要classProbs=TRUE
    verbose = TRUE )

print(race_results|>collect_metrics()) #展示模型结果

best_workflow_id <- race_results %>%
  rank_results() %>%                                       # 按指定指标排序
  filter(.metric == "roc_auc") %>%
  select(wflow_id, .metric, mean , rank) %>% #展示指定的模型
  filter(rank==1) %>%
  pull(wflow_id)

# 11. 获取选择最佳模型对应的工作流
best_workflow <- workflows %>%
  extract_workflow(best_workflow_id)
# 12. 把最佳模型应用到测试数据集,评估泛化能力
final_results <- last_fit(best_workflow,
                         split =split,
                         )

# 13.输出测试集上的泛化性能
collect_metrics(final_results)
```
```{r}
# best_param <- select_best(tune_results, metric) # or other `select_*()`
#  wflow <- finalize_workflow(wflow, best_param)  # or just `finalize_model()`
#  wflow_fit <- fit(wflow, data_set)
final_model <- best_workflow|>fit(train)
```

# final_model
```{r}
final_fit <-final_model

final_result <- final_fit |> predict( train, type='prob')|>
           bind_cols(train|>mutate(loan_status=factor(loan_status, levels = c(0, 1))))

final_result |> 
           roc_auc(loan_status, .pred_0,event_level = 'first')

final_roc_curve <-
  final_result|> 
           roc_curve(loan_status, .pred_0,event_level = 'first')
  
final_roc_curve |> autoplot(x)

```

# predict

```{r}
best_fit <- final_fit
test_predictions <- predict(best_fit, test, type = "class")

submission <- sample_submission %>%
mutate(loan_status = test_predictions$.pred_class)

write_csv(submission, "submission.csv")
```

# submit to kaggle
```{r}
# submit latest submission.csv
system('kaggle competitions submit -c playground-series-s4e10 -f submission.csv -m "glm logistic local 0.90"')
Sys.sleep(5)
# get latest score 
system('kaggle competitions submissions -q -c playground-series-s4e10')
```

# combined eda
```{r}
#| fig.height: 24
#| fig.width: 6 

combined_df <- bind_rows(list('train'=train,'test'=test),.id ='source' )
combined_df |>glimpse( )
num_fe <- combined_df|>select(where(is.numeric)) |>select(-id)|>names()
text_fe <-combined_df|>select(where(is.character))|>select(-source)|>names()
combined_df |>
  pivot_longer(cols=num_fe)|>
  ggplot(aes(x= log1p(value),fill=source))+
  geom_density(alpha=0.5)+
  facet_wrap(~name,ncol = 1,scales = 'free')

```

