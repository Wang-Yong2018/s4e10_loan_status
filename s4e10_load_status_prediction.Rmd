---
title: "s4e10_load_approval_status"
author: "WangYong"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# load data
```{r}
library(tidyverse)
library(tidymodels)
#library( ParBayesOptimization)
library(themis)

data_path <- '../input/playground-series-s4e10/'
train <- read_csv(file.path(data_path, "train.csv")) #|> 
  #mutate(loan_status=as.factor(loan_status))
test <- read_csv(file.path(data_path, "test.csv")) 
sample_submission <- read_csv(file.path(data_path, "sample_submission.csv")) 
```
# EDA
## quick skim
```{r}
train|> ggplot(aes(x=loan_status))+geom_bar()
skimr::skim(train)
skimr::skim(test)
```

# split the data 
```{r}
set.seed(42)

split <- initial_split(train, prop = 0.8, strata = loan_status)
train_data <- training(split)
test_data <- testing(split)

```

# feature engineering 
```{r}
rcp_baseline <-
  recipe(loan_status ~ ., data = train_data) |>
  update_role(id, new_role='ID', )|>
  step_mutate(loan_status=as.factor(loan_status),skip=T)|>
  step_log(all_numeric_predictors(),offset = 1, skip = FALSE) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_unknown(all_nominal_predictors()) |>
  step_impute_median(all_numeric_predictors())|> 
  step_nzv(all_predictors())|>
  step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())|> # Scale numeric predictors
  check_missing(all_predictors())

rcp_baseline |>prep()|>juice() |>glimpse()
```

## resampling (upsampling -example)
```{r}
# Use `themis` package for resampling
library(themis)
# Option 1: Upsampling (simplest)
loan_recipe_upsampled <- 
  rcp_baseline |>
  step_upsample(loan_status, over_ratio = 1)
```

# modeling 
## model engine setup
```{r}
  
library(bonsai)
library(lightgbm)


model <- 
  logistic_reg() |>
  set_engine("glm", family = "binomial")|>
  set_mode('classification')

boost_tree_lgbm_spec <- 
  boost_tree(
    trees = 500,
   tree_depth = 5,
   learn_rate =  0.001,
   min_n = 85,
   loss_reduction = 0
  ) %>% 
  set_engine(engine = "lightgbm",
             is_unbalance = TRUE,
             num_leaves = 713,
             num_threads = 12
       #      boosting = "goss"   # this may slow the system
             ) %>%
  set_mode(mode = "classification") 

```

## fit
```{r}
glm_fit <-
  workflow() |>
  add_recipe(loan_recipe_upsampled) |>
  add_model(model)|>
  fit(data = train_data)

simple_glm_probs <-
  predict(glm_fit, test_data, type = "prob") %>%
  bind_cols(test_data|>mutate(loan_status=factor(loan_status, levels = c(0, 1))))
  #bind_cols(test_data)

simple_glm_roc <- 
  simple_glm_probs %>% 
  roc_curve(loan_status, .pred_0)

simple_glm_probs %>% roc_auc(loan_status, .pred_0)


autoplot(simple_glm_roc )

```
## lightgbm
```{r}

                   
lgbm_fit <- 
  workflow(loan_recipe_upsampled,
           boost_tree_lgbm_spec)|>
  fit(train_data)

lgbm_fit_probs <-
  predict(lgbm_fit, test_data, type = "prob") %>%
  bind_cols(test_data|>mutate(loan_status=factor(loan_status)))

lgbm_fit_roc <- 
  lgbm_fit_probs %>% 
  roc_curve(loan_status, .pred_0)

lgbm_fit_probs %>% roc_auc(loan_status, .pred_0)


autoplot(lgbm_fit_roc )

```

# predict

```{r}
test_predictions <- predict(fit, test, type = "prob")

submission <- sample_submission %>%
mutate(failure = test_predictions$.pred_1)

write_csv(submission, "submission.csv")
```

